{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Z1MZ6mxp2j",
        "outputId": "159e6777-b457-491c-e5bf-896dbbed650c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medpy\n",
            "  Downloading MedPy-0.4.0.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from medpy) (1.22.4)\n",
            "Collecting SimpleITK>=1.1.0 (from medpy)\n",
            "  Downloading SimpleITK-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-py3-none-any.whl size=214946 sha256=7a961f9fcf246da9c61ad16498cad183aa90d98f34c8dec022d50c2842d2197a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d4/32/c7/6380ab2edb8cca018d39a0f1d43250fd9791922c963117de46\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.2.1 medpy-0.4.0\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/DIAGNijmegen/picai_labels\n",
        "#!mv /content/picai_labels /content/drive/MyDrive/picai-challenge-data\n",
        "!pip install medpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de5K0H6cTzGq",
        "outputId": "dd1d6518-09a9-4df5-838b-ba5972bdf3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from medpy.io import load\n",
        "import torchvision\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5aV_tFV-YyU"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7QAl2lq8TiT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from zipfile import ZipFile\n",
        "class picai_handler:\n",
        "  \n",
        "  def __init__(self, path = '/content/drive/MyDrive', howMany = 5):\n",
        "    self.howMany = howMany\n",
        "    if(self.doPaths(path) == -1):\n",
        "      return None\n",
        "    if(self.download_zips() == -1):\n",
        "      return None\n",
        "    self.extract_zips()\n",
        "\n",
        "  def doPaths(self, path):\n",
        "    self.zipPaths = {}\n",
        "    self.dataFolder = ''\n",
        "    self.zipFolder = ''\n",
        "    if (path[-1] == '/'):\n",
        "      path = path[:-1]\n",
        "    if (path[0] != '/'):\n",
        "      path = '/'+path\n",
        "    if not (os.path.isdir(path)):\n",
        "      print(\"Path is not a directory.\")\n",
        "      return -1\n",
        "    self.dataFolder = path + '/picai-challenge-data'\n",
        "\n",
        "    if not (os.path.isdir(self.dataFolder)):\n",
        "      os.mkdir(self.dataFolder)\n",
        "    self.zipFolder = self.dataFolder+'/zips'\n",
        "    if not (os.path.isdir(self.zipFolder)):\n",
        "      os.mkdir(self.zipFolder)\n",
        "    self.unzippedFolder = self.dataFolder+\"/unzipped\"\n",
        "    if not (os.path.isdir(self.unzippedFolder)):\n",
        "      os.mkdir(self.unzippedFolder)\n",
        "\n",
        "    for x in range(self.howMany):\n",
        "      self.zipPaths[x] = ('picai_public_images_fold'+str(x)+'.zip')\n",
        "    self.zipPaths[\"license\"] = \"LICENSE\"\n",
        "    self.zipPaths[\"readme\"] = \"README.md\"\n",
        "  \n",
        "  def download_zips(self):\n",
        "    howManyZips = self.howMany\n",
        "    if(howManyZips > 5):\n",
        "      print(\"Too many ZIP files specified. Actual PICAI only has max of 5.\")\n",
        "      return -1\n",
        "    for key, fileName in self.zipPaths.items():\n",
        "      if (isinstance(key,int)):\n",
        "        if key < howManyZips:\n",
        "          pass\n",
        "        else:\n",
        "          continue\n",
        "      totName = self.zipFolder+'/'+fileName\n",
        "      if not(os.path.isfile(totName)):\n",
        "        print(\"Downloading \"+fileName)\n",
        "        File = requests.get('https://zenodo.org/record/6624726/files/'+fileName+'?download=1', stream = True) \n",
        "        with open(totName, \"wb\") as fule: \n",
        "          for block in File.iter_content(chunk_size = 1024):\n",
        "            if block: \n",
        "              fule.write(block)\n",
        "        print(\"Downloaded \"+fileName)\n",
        "      else:\n",
        "        print(fileName + \" already exists in \" + self.zipFolder)\n",
        "  \n",
        "  def extract_zips(self):\n",
        "\n",
        "    for x in range(self.howMany):\n",
        "      \n",
        "      if not(os.path.isdir(self.unzippedFolder + '/' + self.zipPaths[x][:-4])):\n",
        "        with ZipFile(self.zipFolder+'/'+ self.zipPaths[x], 'r') as zap:\n",
        "          print(\"Extracting \" + self.zipPaths[x])\n",
        "          zap.extractall(self.unzippedFolder + '/' + self.zipPaths[x][:-4])\n",
        "          print('Done!')\n",
        "      else:\n",
        "        print(self.unzippedFolder + '/' + self.zipPaths[x][:-4]+' already exists in', self.unzippedFolder)\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtQOkuPgUHwt"
      },
      "outputs": [],
      "source": [
        "#For google colab, outputs the folder to My Drive of the google drive.\n",
        "#picai = picai_handler()\n",
        "\n",
        "#General case, outputs the folder to current directory.\n",
        "#picai = picai_handler(os.getcwd(), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D891U4iI71pv"
      },
      "outputs": [],
      "source": [
        "#!rsync -a /content/drive/MyDrive/picai-challenge-data/unzipped/picai_public_images_fold0/ /content/drive/MyDrive/picai-challenge-data/merged_unzipped/\n",
        "#!rsync -a /content/drive/MyDrive/picai-challenge-data/unzipped/picai_public_images_fold1/ /content/drive/MyDrive/picai-challenge-data/merged_unzipped/\n",
        "#!rsync -a /content/drive/MyDrive/picai-challenge-data/unzipped/picai_public_images_fold2/ /content/drive/MyDrive/picai-challenge-data/merged_unzipped/\n",
        "#!rsync -a /content/drive/MyDrive/picai-challenge-data/unzipped/picai_public_images_fold3/ /content/drive/MyDrive/picai-challenge-data/merged_unzipped/\n",
        "#!rsync -a /content/drive/MyDrive/picai-challenge-data/unzipped/picai_public_images_fold4/ /content/drive/MyDrive/picai-challenge-data/merged_unzipped/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn9Nz_TEDFOI"
      },
      "outputs": [],
      "source": [
        "marksheet = '/content/drive/MyDrive/picai-challenge-data/picai_labels/clinical_information/marksheet.csv'\n",
        "marksheet = pd.read_csv(marksheet)\n",
        "marksheet = marksheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oyvsgPgDEL_8",
        "outputId": "d8c90af7-01a4-4c13-fcb8-7d4e3e369e54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      patient_id  study_id    mri_date  patient_age    psa  psad  \\\n",
              "0          10000   1000000  2019-07-02           73   7.70   NaN   \n",
              "1          10001   1000001  2016-05-27           64   8.70  0.09   \n",
              "2          10002   1000002  2021-04-18           58   4.20  0.06   \n",
              "3          10003   1000003  2019-04-05           72  13.00   NaN   \n",
              "4          10004   1000004  2020-10-21           67   8.00  0.10   \n",
              "...          ...       ...         ...          ...    ...   ...   \n",
              "1495       11471   1001495  2012-08-25           71  12.50  0.21   \n",
              "1496       11472   1001496  2019-06-28           81   5.28  0.12   \n",
              "1497       11473   1001497  2017-09-24           56  29.60  0.34   \n",
              "1498       11474   1001498  2016-05-03           71  12.00   NaN   \n",
              "1499       11475   1001499  2012-12-23           56  15.00  0.46   \n",
              "\n",
              "      prostate_volume histopath_type    lesion_GS lesion_ISUP  case_ISUP  \\\n",
              "0                55.0           MRBx          0+0           0          0   \n",
              "1               102.0            NaN          NaN         NaN          0   \n",
              "2                74.0            NaN          NaN         NaN          0   \n",
              "3                71.5          SysBx          0+0           0          0   \n",
              "4                78.0     SysBx+MRBx      0+0,0+0         0,0          0   \n",
              "...               ...            ...          ...         ...        ...   \n",
              "1495             62.0           MRBx  3+4,N/A,3+3         2,1          2   \n",
              "1496             44.0     SysBx+MRBx          3+4           2          2   \n",
              "1497             87.0           MRBx          0+0           0          0   \n",
              "1498             83.0           MRBx          3+3           1          1   \n",
              "1499             33.0           MRBx          4+5           5          5   \n",
              "\n",
              "     case_csPCa  \n",
              "0            NO  \n",
              "1            NO  \n",
              "2            NO  \n",
              "3            NO  \n",
              "4            NO  \n",
              "...         ...  \n",
              "1495        YES  \n",
              "1496        YES  \n",
              "1497         NO  \n",
              "1498         NO  \n",
              "1499        YES  \n",
              "\n",
              "[1500 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-effc7fd4-ff18-4230-9e9e-ce470ccc37ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>study_id</th>\n",
              "      <th>mri_date</th>\n",
              "      <th>patient_age</th>\n",
              "      <th>psa</th>\n",
              "      <th>psad</th>\n",
              "      <th>prostate_volume</th>\n",
              "      <th>histopath_type</th>\n",
              "      <th>lesion_GS</th>\n",
              "      <th>lesion_ISUP</th>\n",
              "      <th>case_ISUP</th>\n",
              "      <th>case_csPCa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>1000000</td>\n",
              "      <td>2019-07-02</td>\n",
              "      <td>73</td>\n",
              "      <td>7.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>55.0</td>\n",
              "      <td>MRBx</td>\n",
              "      <td>0+0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>1000001</td>\n",
              "      <td>2016-05-27</td>\n",
              "      <td>64</td>\n",
              "      <td>8.70</td>\n",
              "      <td>0.09</td>\n",
              "      <td>102.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>1000002</td>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>58</td>\n",
              "      <td>4.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>74.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>1000003</td>\n",
              "      <td>2019-04-05</td>\n",
              "      <td>72</td>\n",
              "      <td>13.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>71.5</td>\n",
              "      <td>SysBx</td>\n",
              "      <td>0+0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>1000004</td>\n",
              "      <td>2020-10-21</td>\n",
              "      <td>67</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>78.0</td>\n",
              "      <td>SysBx+MRBx</td>\n",
              "      <td>0+0,0+0</td>\n",
              "      <td>0,0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>11471</td>\n",
              "      <td>1001495</td>\n",
              "      <td>2012-08-25</td>\n",
              "      <td>71</td>\n",
              "      <td>12.50</td>\n",
              "      <td>0.21</td>\n",
              "      <td>62.0</td>\n",
              "      <td>MRBx</td>\n",
              "      <td>3+4,N/A,3+3</td>\n",
              "      <td>2,1</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>11472</td>\n",
              "      <td>1001496</td>\n",
              "      <td>2019-06-28</td>\n",
              "      <td>81</td>\n",
              "      <td>5.28</td>\n",
              "      <td>0.12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>SysBx+MRBx</td>\n",
              "      <td>3+4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>11473</td>\n",
              "      <td>1001497</td>\n",
              "      <td>2017-09-24</td>\n",
              "      <td>56</td>\n",
              "      <td>29.60</td>\n",
              "      <td>0.34</td>\n",
              "      <td>87.0</td>\n",
              "      <td>MRBx</td>\n",
              "      <td>0+0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>11474</td>\n",
              "      <td>1001498</td>\n",
              "      <td>2016-05-03</td>\n",
              "      <td>71</td>\n",
              "      <td>12.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>83.0</td>\n",
              "      <td>MRBx</td>\n",
              "      <td>3+3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>11475</td>\n",
              "      <td>1001499</td>\n",
              "      <td>2012-12-23</td>\n",
              "      <td>56</td>\n",
              "      <td>15.00</td>\n",
              "      <td>0.46</td>\n",
              "      <td>33.0</td>\n",
              "      <td>MRBx</td>\n",
              "      <td>4+5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-effc7fd4-ff18-4230-9e9e-ce470ccc37ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-effc7fd4-ff18-4230-9e9e-ce470ccc37ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-effc7fd4-ff18-4230-9e9e-ce470ccc37ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "marksheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeIndXMZDkwZ",
        "outputId": "1bcf94e6-0e74-4929-c893-78affc3812f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "marksheet.set_index(\"study_id\")[\"case_ISUP\"][1001495]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ0zBjUpd5vH"
      },
      "outputs": [],
      "source": [
        "class dataset_OLD():\n",
        "  def __init__(self, img_dir, label_dir, marksheet, transform=None, target_transform=None, resizeLen = 500):\n",
        "    \n",
        "    self.img_names = []\n",
        "    self.label_dir = label_dir\n",
        "    self.resizeLen = resizeLen\n",
        "    for entry in os.scandir(label_dir):\n",
        "      self.img_names.append(entry.name[:-7])\n",
        "\n",
        "    self.marksheet = pd.read_csv(marksheet)\n",
        "    self.marksheet = self.marksheet.set_index(\"study_id\")[\"case_ISUP\"]\n",
        "    \n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "  def length(self):\n",
        "    return len(self.img_names)\n",
        "  def getitem(self, idx):\n",
        "    label_path = self.label_dir+ '/' + self.img_names[idx] + '.nii.gz'\n",
        "    img_path = self.img_dir + '/' + self.img_names[idx][:5] + '/'+ self.img_names[idx] +'_t2w.mha'\n",
        "    ISUP_case = self.marksheet[int(self.img_names[idx][-7:])]\n",
        "    image, header = load(img_path)\n",
        "    label, label_header = load(label_path)\n",
        "    image = torch.from_numpy(image.transpose(2,0,1).astype(np.int16))\n",
        "    label = torch.from_numpy(label.transpose(2,0,1).astype(np.int16))\n",
        "    resizer = torchvision.transforms.Resize((self.resizeLen,self.resizeLen), antialias=False)\n",
        "    image = resizer(image)\n",
        "    label = resizer(label)\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return image, label, ISUP_case\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class dataset(Dataset):\n",
        "  def __init__(self, img_dir, label_dir, marksheet, transform=None, target_transform=None, resizeLen = (25,100,100), fileI = None, fileL = None):\n",
        "    \n",
        "    self.img_names = []\n",
        "    self.label_dir = label_dir\n",
        "    for entry in os.scandir(label_dir):\n",
        "      self.img_names.append(entry.name[:-7])\n",
        "    self.marksheet = pd.read_csv(marksheet)\n",
        "    self.marksheet = self.marksheet.set_index(\"study_id\")[\"case_ISUP\"]\n",
        "    self.resizer = torchvision.transforms.Resize((resizeLen[1],resizeLen[2]), antialias=False)\n",
        "    self.resizer2 = torchvision.transforms.Resize((resizeLen[0],resizeLen[2]), antialias=False)\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "    self.storeI = []\n",
        "    self.storeL = []\n",
        "    if not (fileI and fileL):\n",
        "      for idx in range(len(self.img_names)):\n",
        "        \n",
        "        img_path = self.img_dir + '/' + self.img_names[idx][:5] + '/'+ self.img_names[idx] +'_t2w.mha'\n",
        "        label_path = self.label_dir+ '/' + self.img_names[idx] + '.nii.gz'\n",
        "        image, header = load(img_path)\n",
        "        label, label_header = load(label_path)\n",
        "        image = torch.from_numpy(image.transpose(2,0,1).astype(np.int16))\n",
        "        label = torch.from_numpy(label.transpose(2,0,1).astype(np.int16))\n",
        "        image = self.resizer(image)\n",
        "        image = self.resizer2(image.permute(1,0,2)).permute(1,0,2).reshape(1,resizeLen[0],resizeLen[1],resizeLen[2]).numpy()\n",
        "        label = self.resizer(label)\n",
        "        label = self.resizer2(label.permute(1,0,2)).permute(1,0,2).reshape(1,resizeLen[0],resizeLen[1],resizeLen[2]).numpy()\n",
        "        self.storeI.append(image)\n",
        "        self.storeL.append(label)\n",
        "      self.storeI = np.concatenate(self.storeI)\n",
        "      self.storeL = np.concatenate(self.storeL)\n",
        "    else:\n",
        "      self.storeI = np.load(fileI)\n",
        "      self.storeL = np.load(fileL)\n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "  \n",
        "  def __getitem__(self, idx, permute = (0,1,2)):\n",
        "    ISUP_case = self.marksheet[int(self.img_names[idx][-7:])]\n",
        "    image = torch.from_numpy(self.storeI[idx])\n",
        "    label = torch.from_numpy(self.storeL[idx])\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "\n",
        "    return image.permute(permute), label.permute(permute), ISUP_case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzcSbXbNuXaL"
      },
      "outputs": [],
      "source": [
        "#dataset = datasetdataset('/content/drive/MyDrive/picai-challenge-data/merged_unzipped', '/content/drive/MyDrive/picai-challenge-data/picai_labels/csPCa_lesion_delineations/human_expert/resampled', None, None, 200)\n",
        "#I = 0\n",
        "#for x in range(dataset.length()):\n",
        "  #if dataset.getitem(x)[1].sum() > 0:\n",
        "    #I+=1\n",
        "#print(I)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JagtavvbV4V"
      },
      "outputs": [],
      "source": [
        "# dataset = datasetdataset('/content/drive/MyDrive/picai-challenge-data/merged_unzipped', '/content/drive/MyDrive/picai-challenge-data/picai_labels/csPCa_lesion_delineations/AI/Bosma22a','/content/drive/MyDrive/picai-challenge-data/picai_labels/clinical_information/marksheet.csv', None, None, resizeLen = 104)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5ZtWLTCHWoj"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "merged_unzipped = '/content/drive/MyDrive/picai-challenge-data/merged_unzipped'\n",
        "lesion_delin = '/content/drive/MyDrive/picai-challenge-data/picai_labels/csPCa_lesion_delineations/AI/Bosma22a'\n",
        "marksheet_p = '/content/drive/MyDrive/picai-challenge-data/picai_labels/clinical_information/marksheet.csv'\n",
        "fileI = \"/content/drive/MyDrive/picai-challenge-data/50_104_104I.npy\"\n",
        "fileL = \"/content/drive/MyDrive/picai-challenge-data/50_104_104L.npy\"\n",
        "dataset = dataset(merged_unzipped, lesion_delin,marksheet_p, None, None, resizeLen = (50,104,104), fileI = fileI, fileL = fileL)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xThsWyKNKeD"
      },
      "outputs": [],
      "source": [
        "#np.save(\"/content/drive/MyDrive/picai-challenge-data/50_104_104I\",dataset.badIdeaI)\n",
        "#np.save(\"/content/drive/MyDrive/picai-challenge-data/50_104_104L\", dataset.badIdeaL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8iCsLxM6RgO",
        "outputId": "577f5510-81f2-47f4-f163-d6f3afc5b470"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50, 104, 104])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "for batch in loader:\n",
        "  a,b,c = batch\n",
        "  break\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33vtNtvhbNuX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# class Autoencoder(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "\n",
        "#         # Encoder layers\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(16, 16, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(16, 16, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "#             nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.MaxPool3d(kernel_size=(1,2,2), stride=2),\n",
        "#             nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.MaxPool3d(kernel_size=(1,2,2), stride=2)\n",
        "#         )\n",
        "\n",
        "#         # Decoder layers\n",
        "#         self.decoderR = nn.Sequential(\n",
        "#             nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=(0,1,1)),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(32,32,3,1,1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(32,32,3,1,1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.ConvTranspose3d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=(0,1,1)),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(16,16,3,1,1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(16,16,3,1,1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "#             nn.Conv3d(1,1,3,1,1),\n",
        "#             nn.Sigmoid(),\n",
        "#             nn.Conv3d(1,1,3,1,1),\n",
        "#             nn.Sigmoid()\n",
        "#         )\n",
        "#         # self.decoder = nn.Sequential(\n",
        "#         #     nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=(0,1,1)),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Conv3d(32,32,3,1,1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Conv3d(32,32,3,1,1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.ConvTranspose3d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=(0,1,1)),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Conv3d(16,16,3,1,1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Conv3d(16,16,3,1,1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "#         #     nn.Conv3d(1,1,3,1,1),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Conv3d(1,1,3,1,1),\n",
        "#         #     nn.ReLU()\n",
        "#         # )\n",
        "#         # self.linear = nn.Sequential(\n",
        "#         #     nn.Conv3d(64,1,1,1,0),\n",
        "#         #     nn.Flatten(),\n",
        "#         #     nn.Linear(1183, 845),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(845,169),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(169, 6),\n",
        "#         #     nn.ReLU()\n",
        "#         # )\n",
        "#     def forward(self, x):\n",
        "#         # Encoder\n",
        "#         encoded_vals = self.encoder(x)\n",
        "#         # Decoder\n",
        "#         #ISUP = self.linear(encoded_vals)\n",
        "#         reconstructed = self.decoderR(encoded_vals)\n",
        "#         #labeled = self.decoder(encoded_vals)\n",
        "#         return reconstructed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFThkPbuSW7M"
      },
      "outputs": [],
      "source": [
        "# from torch.nn.modules.flatten import Flatten\n",
        "# class Autoencoder(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "\n",
        "#         # Encoder layers\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Conv3d(1, 8, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2)),\n",
        "#             nn.Conv3d(8, 64, kernel_size=3, stride=1, padding=1),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "#         )\n",
        "\n",
        "#         # Decoder layers\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.ConvTranspose3d(64, 8, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose3d(8, 1, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             nn.ReLU()\n",
        "#             # nn.ConvTranspose3d(16, 1, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             # nn.Tanh()\n",
        "#         )\n",
        "\n",
        "#         self.decoder2 = nn.Sequential(\n",
        "#             nn.ConvTranspose3d(64, 8, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             nn.ReLU(),\n",
        "#             nn.ConvTranspose3d(8, 1, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             nn.ReLU()\n",
        "#             # nn.ConvTranspose3d(16, 1, kernel_size=3, stride=(1,2,2), padding=1, output_padding=(0,1,1)),\n",
        "#             # nn.Tanh()\n",
        "#         )\n",
        "#         self.linear =  nn.Sequential(nn.Conv3d(64,1, kernel_size=(1,2,2), stride=1),\n",
        "#                                      nn.MaxPool3d(kernel_size=(5,2,2), stride=(5,2,2)), \n",
        "#                                      nn.ReLU(),\n",
        "#                                      nn.Flatten(),\n",
        "#                                      nn.Linear(1440, 720),\n",
        "#                                      nn.ReLU(),\n",
        "#                                      nn.Linear(720, 360),\n",
        "#                                      nn.ReLU(),\n",
        "#                                      nn.Linear(360,6)\n",
        "#                                      )\n",
        "                                     \n",
        "#     def forward(self, x):\n",
        "#         # Encoder\n",
        "#         x = self.encoder(x)\n",
        "#         # Decoder\n",
        "#         recon = self.decoder(x)\n",
        "#         labeled = self.decoder2(x)\n",
        "#         out = self.linear(x)\n",
        "#         return labeled, recon, out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True))\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "    \n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels))\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "    \n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels//2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        \n",
        "        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n",
        "                        diffY//2, diffY-diffY//2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "a5mgvTFks0IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        \n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024//factor)\n",
        "\n",
        "        self.up1 = Up(1024, 512//factor, bilinear)\n",
        "        self.up2 = Up(512, 256//factor, bilinear)        \n",
        "        self.up3 = Up(256, 128//factor, bilinear)        \n",
        "        self.up4 = Up(128, 64, bilinear)        \n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "        self.linear =  nn.Sequential(nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)), \n",
        "                                     nn.Flatten(),\n",
        "                                     nn.Linear(4608, 2000),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(2000, 1000),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(1000,6)\n",
        "                                     )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        out = self.linear(x5)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits, out"
      ],
      "metadata": {
        "id": "xg_6O8Y6s8N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef_metric(pred, label):\n",
        "    intersection = 2.0 * (pred * label).sum()\n",
        "    union = pred.sum() + label.sum()\n",
        "    if pred.sum() == 0 and label.sum() == 0:\n",
        "        return 1.\n",
        "    return intersection / union\n",
        "\n",
        "def dice_coef_loss(pred, label):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * (pred * label).sum() + smooth\n",
        "    union = pred.sum() + label.sum() + smooth\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "def bce_dice_loss(pred, label):\n",
        "    dice_loss = dice_coef_loss(pred, label)\n",
        "    bce_loss = nn.BCELoss()(pred, label)\n",
        "    return dice_loss + bce_loss"
      ],
      "metadata": {
        "id": "XhYdKkwouBru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDaqhseTedm-"
      },
      "outputs": [],
      "source": [
        "encoder = UNet(1,1).to(device)\n",
        "encoder.train()\n",
        "encoderO = torch.optim.Adam(encoder.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBDLJXPkF3sS",
        "outputId": "53ac4466-19f7-4b3f-a4e3-3a31f8af1700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 1, 104, 104]) torch.Size([50, 6])\n"
          ]
        }
      ],
      "source": [
        "stuff = torch.randn(50,1,104,104).to(device)\n",
        "img, out = encoder(stuff)\n",
        "print(img.shape, out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace(new_val, lst):\n",
        "  ls = []\n",
        "  for i in lst:\n",
        "    if i>0:\n",
        "      ls.append(int(new_val))\n",
        "    else:\n",
        "      ls.append(int(i))\n",
        "  return ls\n"
      ],
      "metadata": {
        "id": "MdinBisY710S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# arr = np.random.randn(50, 1,104,104)\n",
        "# k = [arr[i].max() for i in range(50)]\n",
        "# for x, batch in enumerate(loader):\n",
        "#   images, labeled, ISUP_case = batch\n",
        "#   images = images.permute(1,0,2,3)\n",
        "#   labeled = labeled.permute(1,0,2,3)\n",
        "#   arr = labeled.detach().numpy()\n",
        "#   k = [arr[i].max() for i in range(len(arr))]\n",
        "#   k = replace(ISUP_case, k)\n",
        "#   k = torch.as_tensor(k)\n",
        "\n",
        "#   # ISUP_case = nn.functional.one_hot(k, 6).to(device)\n",
        "#   print(k)\n",
        "#   break"
      ],
      "metadata": {
        "id": "Hdg7bNoe3YWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7r0IRsN9MGq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc_curve = []\n",
        "loss_curve = []\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(1,epochs):\n",
        "  train_loss = 0\n",
        "  z = 0\n",
        "  acc = 0\n",
        "  for x, batch in enumerate(loader):\n",
        "    images, labeled, ISUP_case = batch\n",
        "    \n",
        "    # print( k)\n",
        "    if(torch.sum(labeled) == 0):\n",
        "      if(np.random.rand() <  0.7):\n",
        "        continue\n",
        "\n",
        "    images = images.to(device).float()\n",
        "    labeled = labeled.to(device).float()\n",
        "    \n",
        "    # ISUP_case = nn.functional.one_hot(ISUP_case).to(device)\n",
        "    images = images.permute(1,0,2,3)\n",
        "    labeled = labeled.permute(1,0,2,3)\n",
        "    k = [labeled[i].max() for i in range(len(labeled))]\n",
        "    # print(k)\n",
        "    k = replace(int(ISUP_case), k)\n",
        "    k = torch.as_tensor(k).to(device)\n",
        "    encoderO.zero_grad()\n",
        "    \n",
        "    # labelO, reconO, out = encoder(images)\n",
        "    out,ISUPO = encoder(images)\n",
        "    loss = bce_dice_loss(out,labeled)+nn.functional.cross_entropy(ISUPO, k)\n",
        "    # + nn.functional.mse_loss(labelO, labeled) + nn.functional.cross_entropy(ISUPO, ISUP_case)\n",
        "    loss.backward()\n",
        "    acc += torch.sum(torch.argmax(ISUPO, 1) == k).item()\n",
        "    # print(torch.sum(torch.argmax(ISUPO, 1) == k))\n",
        "    train_loss+=loss.detach().item()\n",
        "    z+=1\n",
        "    encoderO.step()\n",
        "    # if(z >= 5):\n",
        "    #   break\n",
        "    if(epoch%2 == 0 and x == 100):\n",
        "      plt.subplot(1,3,1)\n",
        "      plt.imshow(labeled[25][0].cpu().detach().numpy(), cmap = 'gray')\n",
        "      plt.subplot(1,3,2)\n",
        "      plt.imshow(out[25][0].cpu().detach().numpy(), cmap = 'gray')\n",
        "      plt.subplot(1,3,3)\n",
        "      plt.imshow( images[25][0].cpu().detach().numpy(), cmap = 'gray')\n",
        "      plt.show()\n",
        "  acc_curve.append(acc/(50*z)*100)\n",
        "  loss_curve.append(train_loss/z)\n",
        "  print(\"\\nEpoch: \",epoch,\" loss : \",float(train_loss/z), \"Accuracy: \", acc/(50*z)*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle_out = open(\"model.pkl\",\"wb\")\n",
        "pickle.dump(encoderO, pickle_out)\n",
        "pickle_out.close()"
      ],
      "metadata": {
        "id": "RE-Poqb_nb75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.plot(acc_curve)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(loss_curve)\n",
        "plt.title(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FUZsFt_JakRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}